\documentclass{article}
\input{preamble.tex}

% Authors and affiliations
\title{The Ensemble Kalman Update is an Empirical Matheron Update}

\author{
  Dan MacKinlay \\
  CSIRO's Data61 \\
  \texttt{dan@danmackinlay.name} \\
}

% You may provide any keywords that you find helpful for describing your paper
\date{February 2025}

\begin{document}


\begin{abstract}
The Ensemble Kalman Filter (EnKF) is a widely used method for data assimilation in high-dimensional systems. In this paper, we show that the ensemble update step of the EnKF is equivalent to an empirical Matheron update for Gaussian random variables. By explicitly representing the ensemble mean and covariance using empirical approximations, we establish this equivalence. This connection provides a probabilistic interpretation of the EnKF and opens avenues for improving ensemble-based data assimilation methods by leveraging properties of the Matheron update.

While this connection is simple, it seems not to be widely known. Explicit attempts to unify the literatures that gave birth to these concepts are rare, and experts in both domains do not exploit the connection.

This paper exists to provide a short introduciton to the connection, together with the necessary definitions so that it is intelligible to as broad an audience as possible.
\end{abstract}

\section{Introduction}
The Ensemble Kalman Filter (EnKF)~\citep{Evensen2003Ensemble,Evensen2009Data} is a cornerstone in data assimilation for large-scale dynamical systems due to its computational efficiency and scalability.
The EnKF approximates the state estimation problem by evolving an ensemble of state vectors through the model dynamics and updating them using observational data.

Separately, the Matheron update provides a sample-based method for conditioning Gaussian random variables on observations~\citep{Doucet2010Note,Wilson2020Efficiently,Wilson2021Pathwise}.
This approach is well-established in geostatistics and spatial statistics but the connection to ensemble methods in data assimilation seems not to be well-known.

In this work, we establish that the ensemble update step in the EnKF is equivalent to an empirical Matheron update, by putting them on a common probabilistic footing.
By explicitly representing the ensemble mean and covariance using empirical approximations, we demonstrate this equivalence.
Recognizing this connection provides an alternative  probabilistic foundation for the EnKF and suggests potential improvements in ensemble data assimilation techniques by leveraging the properties of the Matheron update.
Conversely, the analytic Matheron updates in the literature could benefit from the many computational optimisations arising from the data assimilation community.

\subsection{Notation}

We write random variates sans serif, $\vrv{x}$.
Equality in distribution is $\disteq$.
The law, or measure, of a random variate $\vrv{x}$ is denoted $\Law[\vrv{x}]$,
Thus $\left(\Law[\vrv{x}]=\Law[\vrv{y}]\right) \Rightarrow \left(\vrv{x}\disteq\vrv{y}\right)$.
Mnemonically, samples drawn from the $\Law[\vrv{x}]$ are written with a serif $\vv{x}\sim\Law$.
We use a hat to denote empirical estimates, e.g. \(\ELaw[\mm{X}]\) is the empirical law induced by the sample matrix \(\mm{X}\).
Where there is no ambiguity we suppress the sample matrix, writing simply \(\widehat{\Law}\).

This measure notation from probability theory is unpopular in both machine learning and data assimilation contexts who prefer densities to be implied for all random variables.
We attempt a translation table in apprendix~\ref{sec:densities-please}.

\section{Matheron Update}

The Matheron update is a technique for sampling from the conditional distribution of a Gaussian random variable given observations, without explicitly computing the posterior covariance \citep{Doucet2010Note,Wilson2020Efficiently,Wilson2021Pathwise}.

\begin{lemma}[Matheron Update]
Given a jointly Gaussian vector
\begin{align}
    \begin{bmatrix} \vrv{x} \\ \vrv{y} \end{bmatrix}
    &\sim \Normal\left(\begin{bmatrix} \vv{m}_{\vrv{x}} \\ \vv{m}_{\vrv{y}} \end{bmatrix}, \begin{bmatrix} \mm{C}_{\vrv{xx}} & \mm{C}_{\vrv{xy}} \\ \mm{C}_{\vrv{yx}} & \mm{C}_{\vrv{yy}} \end{bmatrix}\right), \label{eq:joint-gaussian}
\end{align}
the conditional $\vrv{x} | \vrv{y} {=} \vv{y}^*$ is equal in distribution to
\begin{align}
    \left(\vrv{x} \gvn \vrv{y} {=} \vv{y}^*\right)
    &\disteq \vrv{x} + \mm{C}_{\vrv{xy}} \mm{C}_{\vrv{yy}}^{-1} \left( \vv{y}^* - \vrv{y} \right).
    \label{eq:matheron-update}
\end{align}
% where $\vv{x}_0$ and $\vv{y}_0$ are samples from the prior distributions of $\vv{x}$ and $\vv{y}$, respectively.
\end{lemma}

\begin{proof}
    A standard property of the Gaussian \citep[e.g.][]{Petersen2012Matrix} is that the conditional distribution of a Gaussian variate  $\vrv{x}$ given $\vrv{y} = \vv{y}^*$ defined as in \eqref{eq:joint-gaussian} is again Gaussian
    \begin{align}
        \left(\vrv{x} \gvn \vrv{y} {=} \vv{y}^*\right)
        \sim\Normal(\vv{m}_{\vrv{x}\gvn\vrv{y}}, \mm{C}_{\vrv{x}\gvn\vrv{y}})\label{eq:conditional-gaussian}
    \end{align}
    with moments
    \begin{align}
        \vv{m}_{\vrv{x}\gvn\vrv{y}}
            &=\Ex [\vrv{x} \gvn \vrv{y} {=} \vv{y}^*] \\
            &= \vv{m}_{\vrv{x}} + \mm{C}_{\vrv{xy}} \mm{C}_{\vrv{yy}}^{-1} \left( \vv{y}^* - \vv{m}_{\vrv{y}} \right), \label{eq:conditional-mean}\\
        \mm{C}_{\vrv{x}\gvn\vrv{y}}
            &= \var \left(\vrv{x} \gvn \vrv{y} {=} \vv{y}^*\right) \\
            &= \mm{C}_{\vrv{xx}} - \mm{C}_{\vrv{xy}} \mm{C}_{\vrv{yy}}^{-1} \mm{C}_{\vrv{yx}}. \label{eq:conditional-cov}
    \end{align}
    % The sample $\vv{x}$ is drawn from $\Normal(\vv{m}_{\vrv{x}\gvn\vrv{y}}, \mm{C}_{\vrv{x}\gvn\vrv{y}})$.
Taking moments of the right hand side of \eqref{eq:matheron-update}
\begin{align}
\Ex\left[\vrv{x}+\mm{C}_{\vrv{xy}} \mm{C}_{\vrv{yy}}^{-1}(\vv{y}^*-\vrv{y})\right]
&=\vv{m}_{\vrv{x}} +\mm{C}_{\vrv{xy}}\mm{C}_{\vrv{yy}}^{-1}(\vv{y}^*-\vv{m}_{\vrv{y}})\\
&=\vv{m}_{\vrv{x}\gvn\vrv{y}}\\
\var\left[\vrv{x}+\mm{C}_{\vrv{xy}} \mm{C}_{\vrv{yy}}^{-1}(\vv{y}^*-\vrv{y})\right]
&=
    \var[\vrv{x}]+\var[\mm{C}_{\vrv{xy}} \mm{C}_{\vrv{yy}}^{-1}(\vv{y}^*-\vrv{y})] \\
    &\hspace{2em} +\var(\vrv{x},\mm{C}_{\vrv{xy}} \mm{C}_{\vrv{yy}}^{-1}(\vv{y}^*-\vrv{y}))
    +\var(\vrv{x},\mm{C}_{\vrv{xy}} \mm{C}_{\vrv{yy}}^{-1}(\vv{y}^*-\vrv{y}))^{\top}\\
&=\mm{C}_{\vrv{x}\vrv{x}} +\mm{C}_{\vrv{xy}} \mm{C}_{\vrv{yy}}^{-1}\mm{C}_{\vrv{yy}} \mm{C}_{\vrv{yy}}^{-1}\mm{C}_{\vrv{yx}}
-  2\mm{C}_{\vrv{xy}} \mm{C}_{\vrv{yy}}^{-1}\mm{C}_{\vrv{yx}}\\
&=\mm{C}_{\vrv{x}\vrv{x}} -\mm{C}_{\vrv{xy}} \mm{C}_{\vrv{yy}}^{-1}\mm{C}_{\vrv{yx}}\\
&=\mm{C}_{\vrv{x}\gvn\vrv{y}}
\end{align}
we see that both first and second moments match.
Since $\Law\left\{\vrv{x} \gvn \vrv{y} {=} \vv{y}^*\right\}$ and
$\Normal(\vv{m}_{\vrv{x}\gvn\vrv{y}}, \mm{C}_{\vrv{x}\gvn\vrv{y}})$ are Gaussian distributions with the same moments, they define the same distribution.
\end{proof}
% Note that this update does not require us to calculate \(\mm{C}_{\vrv{x}\vrv{x}} \)
% and further, may be conducted without needing to evaluate the density of the observation.

This \emph{pathwise} approach to conditioning Gaussian variates has gained currency in machine learning as a tool for sampling and inference in Gaussian proccesses \citep{Wilson2020Efficiently,Wilson2021Pathwise}, notably in generalising to challenging domains such as Riemannian manifolds~\citep{Borovitskiy2020Matern}.


\section{Kalman Filter}
We begin by recalling that in state filtering the goal is to update our estimate of the system state when a new observation becomes available. In a general filtering problem the objective is to form the posterior distribution \(\Law[\vrv{x}_{t+1} \gvn \vrv{x}_t, \vv{y}^*]\) from the prior \(\Law[\vrv{x}_{t+1} \gvn \vrv{x}_t]\) updating with  the new information in the observation \(\vv{y}^*\).

We assume a known observation operator $\op{H}$ such that observations $\vrv{y}$ are a priori related to state \vrv{x} by $\vrv{y}=\op{H}(\vrv{x}\vrv)$; Thus there exists a joint law for the prior random vector
\begin{align}
    \begin{bmatrix}
        \vrv{x}\\
        \vrv{y}
    \end{bmatrix} &= \begin{bmatrix}
        \vrv{x}\\
        \op{H}(\vrv{x})
    \end{bmatrix}\label{eq:joint-law}
    % \eqcolon\Law \left( \begin{bmatrix}
    %     \vrv{x}\\
    %     \vrv{y}
    % \end{bmatrix}\right)
\end{align}
which is determined by the prior state distribution $\Law[\vrv{x}]$ and the observation operator $\op{H}$.
The  \emph {analysis} step, in state filtering parlance, is the update at time $t$ of  \(\Law[\vrv{x}_{t}]\), into the posterior \( \Law[\vrv{x}_t \gvn (\vrv{y}_t{=}\vv{y}_t^*)]\)
i.e. incorporating the likelihood of the observation $\vv{y}_t^*=\vv{y}_t$.
Although  recursive updating in $t$ is the focus of the classic Kalman filter, in this work we are concerned only with the observational update step.
Hereafter we suppress the time index $t$, and consider an individual analysis update.

Suppose that the state and observation noise are independent, and all variates are defined over a finite dimensional real vector space
$\vv{x}\in\mathbb{R}^{D_{\vrv{x}}}, \vv{y}\in \mathbb{R}^{D_{\vrv{y}}}.$
Suppose, moreover, that at the update step our prior belief about $\vrv{x}$ is Gaussian mean \(\vv{m}_{\vrv{x}}\) and covariance \(\mm{C}_{\vrv{xx}}\), that the observation noise is centred Gaussian with covariance \(\mm{R}\), and the observation operator is linear with matrix \(\mm{H}\), so that the observation is related to the state via
\[
\vv{y} = \mm{H}\,\vv{x} + \vv{\varepsilon}, \quad \vv{\varepsilon} \sim \mathcal{N}(0,\mm{R}).
\]
Then the joint distribution of the prior state and observation is Gaussian and \eqref{eq:joint-law} implies that it is
\begin{align}
\begin{bmatrix}
\vrv{x} \\
\vrv{y}
\end{bmatrix}
&\sim \mathcal{N}\!\left(
    \begin{bmatrix}
    \vv{m}_{\vrv{x}} \\
    \vv{m}_{\vrv{y}}
    \end{bmatrix},
    \begin{bmatrix}
    \mm{C}_{\vrv{xx}} & \mm{C}_{\vrv{xy}} \\
    \mm{C}_{\vrv{yx}} & \mm{C}_{\vrv{yy}}
    \end{bmatrix}
    \right)\\
&=\mathcal{N}\!\left(
    \begin{bmatrix}
    \vv{m}_{\vrv{x}} \\
    \mm{H}\,\vv{m}_{\vrv{x}}
    \end{bmatrix},
    \begin{bmatrix}
    \mm{C}_{\vrv{xx}} & \mm{C}_{\vrv{xx}}\,\mm{H}^\top \\
    \mm{H}\,\mm{C}_{\vrv{xx}} & \mm{H}\,\mm{C}_{\vrv{xx}}\,\mm{H}^\top + \mm{R}
    \end{bmatrix}
    \right)
\end{align}
When an observation \(\vv{y}^*\) is obtained, we apply the formulae
\eqref{eq:conditional-gaussian}, \eqref{eq:conditional-mean}, and \eqref{eq:conditional-cov} to calculate
\begin{align}
\left(\vrv{x} \gvn \vrv{y} {=} \vv{y}^*\right)
&\sim\Normal(\vv{m}_{\vrv{x}\gvn\vrv{y}}, \mm{C}_{\vrv{x}\gvn\vrv{y}})\\
\vv{m}_{\vrv{x}\gvn \vv{y}}
&= \vv{m}_{\vrv{x}} + \mm{K} \left(\vv{y}^* - \vv{m}_{\vrv{y}}\right),\\
&= \vv{m}_{\vrv{x}} + \mm{K} \left(\vv{y}^* - \mm{H}\,\vv{m}_{\vrv{x}}\right),\\
\mm{C}_{\vrv{x}\gvn\vrv{y}}
&= \mm{C}_{\vrv{xx}} - \mm{K}\mm{C}_{\vrv{yx}}\\
&= \mm{C}_{\vrv{xx}} - \mm{K}\,\mm{H}\,\mm{C}_{\vrv{xx}}.
\end{align}
where
\begin{align}
\mm{K}
&\coloneq \mm{C}_{\vrv{xy}}\,\mm{H}^\top \left(\mm{C}_{\vrv{yy}}\right)^{-1},\label{eq:kalman-gain}\\
&\coloneq \mm{C}_{\vrv{xx}}\,\mm{H}^\top \left(\mm{H}\,\mm{C}_{\vrv{xx}}\,\mm{H}^\top + \mm{R}\right)^{-1},
\end{align}
is the \emph{Kalman gain}.

Herafter we consider a constant diagonal \(\mm{R}\) for simplicity, so that \(\mm{R}=\rho^2\mm{I}\).

\section{Ensemble Kalman Filter}

In high-dimensional or nonlinear settings, directly computing these posterior updates is often intractable.
The Ensemble Kalman Filter (EnKF) addresses this issue by representing the belief about the state empirically,  via an ensemble of \(N\) state vectors sampled from the prior distribution,
\begin{align}
    \mm{X} = \begin{bmatrix} \vv{x}^{(1)} & \vv{x}^{(2)} & \cdots & \vv{x}^{(N)} \end{bmatrix},
\end{align}
and substituting the empirical measure $\ELaw[\mm{X}]\approx \Law$.

In the Gaussian setting a measure is specified entirely by its first two moments, so we aim to cosntruct empirical measures which match the desired target in terms of these moments.
For convenience, we introduce notation for matrix mean,
\begin{align}
\mmmean{X} &\coloneq \frac{1}{N}\sum_{i=1}^N \vv{x}^{(i)}
\end{align}
and the deviation matrix,
\begin{align}
\mmdev{X} &\coloneq \frac{1}{\sqrt{N-1}} \left( \mm{X} - \mmmean{X} \vv{1}^\top \right), \label{eq:deviation_matrix}
\end{align}
where \(\vv{1}^\top\) is a row vector of \(N\) ones.
The ensemble mean and covariance ae computed from the empirical measure,
\begin{align}
    \widehat{\Ex}[\vrv{x}]\coloneq \Ex_{\vrv{x}\sim \ELaw[\mm{X}]}[ \vrv{x}] =\widehat{\vv{m}}_{\vrv{x}}
&=\mmmean{X}\label{eq:ensemble_mean} & \text{ ensemble mean}\\
% &\coloneq \frac{1}{N} \sum_{i=1}^{N} \vv{x}^{(i)},\\
\widehat{\var}(\vrv{x}) \coloneq\var_{\vrv{x}\sim \ELaw[\mm{X}']} (\vrv{x})=\widehat{\mm{C}}_{\vrv{xx}} &\coloneq \frac{1}{N-1} \sum_{i=1}^{N} \left(\vv{x}^{(i)} - \widehat{\vv{m}}_{\vrv{x}}\right)\left(\vv{x}^{(i)} - \widehat{\vv{m}}_{\vrv{x}}\right)^\top  \\
&=\mmdev{X} \mmdev{X}^\top + (\xi^2\mm{I}),&\text{ ensemble covariance}  \label{eq:ensemble-covariance}
\end{align}
$\vv{\sigma}_{\mm{X}}^2$ is some scalar constant introduces a regularisation to the empirical covariance to ensure it is invertible.
Abusing notation somewhat, we associate a Gaussian distribution with the empirical measure
\begin{align}
\ELaw[\mm{X}] \approx \Normal(\widehat{\Ex}[\vrv{x}], \widehat{\var}(\vrv{x})) = \Normal(\mmmean{X}, \mmdev{X} \mmdev{X}^\top + \xi^2\mm{I}).
\end{align}
This association should be understood purely as a mnemonic device rather than a precise claim about convergence in some metric.
Rigorous convergence of the convergence of such empirical measures to the true distribution is beyond the scope of this short note, but much studied and rather subtle~\citep{LeGland2009Large,Mandel2011Convergence,Kelly2014Wellposedness,Kwiatkowski2015Convergence,DelMoral2017Stability}.
For now, we regard a posterior inference about $\vrv{x}$ given $\vrv{y}=\vv{y}^*$ as successful if we can find  new ensemble $\mm{X}'$ such that, approximately, its empirical moments match the desired target distribution, i.e. we seek to obtain an ensemble $\mm{X}'$ such that
\begin{align}
    \Ex_{\vrv{x}\sim \ELaw[\mm{X}']}[ \vrv{x}] &\approx \Ex_{\vrv{x}\sim (\Law[\vrv{x} \gvn \vrv{y}=\vv{y}^*])} [\vrv{x}]\\
    \var_{\vrv{x}\sim \ELaw[\mm{X}']} (\vrv{x}) &\approx \var_{\vrv{x}\sim (\Law[\vrv{x} \gvn \vrv{y}=\vv{y}^*])} (\vrv{x})
\end{align}
We overload the observation operator to apply to ensemble matrices, writing
\begin{align}
    \mm{Y}\coloneq\op{H}\mm{X} &\coloneq \begin{bmatrix}\op{H}(\vv{x}^{(1)}) & \op{H}(\vv{x}^{(2)})& \dots& \op{H}(\vv{x}^{(N)})\end{bmatrix}.
\end{align}
This also induces an empirical estimate of the observation prior measure $\Law[\vrv{y}]$,
\begin{align}
    \ELaw[\mm{Y}]
    \coloneq \Normal(\mmmean{Y}, \mmdev{Y} \mmdev{Y}^\top + (\upsilon^2\mm{I})).
\end{align}
and in fact an empirical joint
\begin{align}
    \ELaw[{\left[\begin{smallmatrix}
        \mm{X}\\
        \mm{Y}
    \end{smallmatrix}\right]}] &\coloneq \Normal\left(\begin{bmatrix}
        \mmmean{X}\\
        \mmmean{Y}
    \end{bmatrix},
    \begin{bmatrix}
        \mmdev{X} \mmdev{X}^\top + \xi^2\mm{I} & \mmdev{X} \mmdev{Y}^\top \\
        \mmdev{Y} \mmdev{X}^\top  & \mmdev{Y} \mmdev{Y}^\top + \upsilon^2\mm{I}
    \end{bmatrix}
    \right).\label{eq:ensemble-joint}
\end{align}
Here the regularisation term $(\upsilon^2\mm{I})$ is introduced to ensure the empirical covariance is invertible, given that the ensemble of observations is typically rank deficient when $D_{\vrv{y}}>N$.

When a new observation \(\vv{y}^*\) is available, we form a corresponding observation ensemble.
This is achieved by setting
\[
\mm{Y}^* = \vv{y}^* \mathbf{1}^\top,
\]
so that each column of \(\mm{Y}^*\) equals \(\vv{y}^*\).
The Kalman gain in the ensemble setting is constructed by plugging in the empirical ensemble estimates \eqref{eq:ensemble-joint} to \eqref{eq:kalman-gain} obtaining
\begin{align}
\widehat{\mm{K}}= \widehat{\mm{C}}_{\vrv{xx}}\, \op{H}^\top \left(\op{H}\,\widehat{\mm{C}}_{\vrv{xx}}\, \op{H}^\top + \upsilon^2\mm{I} + \rho^2\mm{I}\right)^{-1}\label{eq:ensemble-kalman-gain}
\end{align}
where \(\rho^2\mm{I}\) is the observation error covariance matrix.
The term
$\upsilon^2\mm{I}$ comes from the regularization of the empirical observation covariance (as defined by the ensemble of
$\mm{Y}$), while $\rho^2\mm{I}$ represents the known covariance of the observation noise.
Combining these two gives the effective covariance in the observation space.
For compactness we define \(\gamma^2 \coloneq \upsilon^2 + \rho^2\) so that the combined covariance is \(\mm{C}_{\vrv{yy}} = \mmdev{Y} \mmdev{Y}^\top + \gamma^2\mm{I}\).

Finally, the analysis update for the ensemble is performed by
\begin{align}
    \mm{X}' &= \mm{X} + \widehat{\mm{K}} \left(\mm{Y}^* - \op{H}\mm{X}\right).\label{eq:ensemble-update}
\end{align}
i.e. each ensemble member is updated
\begin{align}
\vv{x}^{(i)}{}' \gets \vv{x}^{(i)} + \widehat{\mm{K}} \left(\vv{y}^* - \op{H}\,\vv{x}^{(i)}\right).
\end{align}

Equating moments, we see that
\begin{align}
\ELaw[\vrv{x}\sim \mm{X}']
% \Law\left\{\mm{X} + \widehat{\mm{K}} \left(\mm{Y}^* - \op{H}\,\mm{X}\right)\right\}.
\approx \Law[\vrv{x} \gvn \vrv{y}=\vv{y}^*]
\end{align}
That is, the EnKF analysis equations \eqref{eq:ensemble-kalman-gain} and \eqref{eq:ensemble-update} can be justified in terms of an empirical approximation to the Gaussian posterior update.

\section{Empirical Matheron Update is equvalent to Ensemble Kalman Update}
In this setting we now have a trivial equivalence of the Matheron update and the EnKF analysis step.
Under the substitution
\begin{align}
    \vv{m}_{\vrv{x}} &\to \mmmean{X}, & \mm{C}_{\vrv{xx}} &\to \mmdev{X} \mmdev{X}^\top + \xi^2\mm{I},\\
    \vv{m}_{\vrv{y}} &\to \mmmean{Y}, & \mm{C}_{\vrv{yy}} &\to \mmdev{Y} \mmdev{Y}^\top + \gamma^2\mm{I},\\
    \mm{C}_{\vrv{xy}} &\to \mmdev{X} \mmdev{Y}^\top, & \mm{C}_{\vrv{yx}} &\to \mmdev{Y} \mmdev{X}^\top,
\end{align}
the Matheron update~\eqref{eq:matheron-update} becomes identical to the ensemble update~\eqref{eq:ensemble-update}.

\section{Computational Complexity}

As is well iunderstood in the EnKF literature, the computational attractiveness of the Ensemble Kalman Filter lies in the fact that the analysis update can be performed using only empirical ensemble statistics, thereby avoiding the direct computation and inversion of high-dimensional covariance matrices.
In contrast, the naive Kalman update must operate directly on these full covariance matrices, which can be prohibitively expensive in high-dimensional settings.

Recall that the ensemble Kalman gain is computed as
\begin{align}
    \widehat{\mm{K}} &= \mmdev{X}\,\mmdev{Y}^\top \left(\mmdev{Y}\,\mmdev{Y}^\top + \gamma^2\mm{I}\right)^{-1},
\end{align}
where \(\gamma^2 = \upsilon^2 + \rho^2\) aggregates the regularization term for the empirical observation covariance (\(\upsilon^2\mm{I}\)) and the intrinsic observation noise (\(\rho^2\mm{I}\)).

Let us break down the cost of this ensemble update:

\begin{enumerate}
    \item \textbf{Forming the Empirical Covariance:}
    Multiplying the \(D_{\vrv{y}}\times N\) matrix \(\mmdev{Y}\) by its transpose (an \(N\times D_{\vrv{y}}\) matrix) requires \(O(D_{\vrv{y}}N^2)\) operations.

    \item \textbf{Inversion of the \(N\times N\) Matrix:}
    Inverting the \(N\times N\) matrix \(\mmdev{Y}^\top \mmdev{Y} + \gamma^2\mm{I}\) costs \(O(N^3)\) operations.

    \item \textbf{Matrix Multiplications to Form the Gain:}
    Multiplying \(\mmdev{X}\) (a \(D_{\vrv{x}}\times N\) matrix) with \(\mmdev{Y}^\top\) (an \(N\times D_{\vrv{y}}\) matrix) requires \(O(D_{\vrv{x}}D_{\vrv{y}}N)\) operations. Additional multiplications involving the inverted \(N\times N\) matrix contribute a further \(O(D_{\vrv{y}}N^2)\) operations.
\end{enumerate}

Summing these contributions, the overall computational cost of the ensemble update is approximately
\[
    O\bigl(D_{\vrv{y}}N^2 + N^3 + D_{\vrv{x}}D_{\vrv{y}}N\bigr).
\]
Since in practical applications the ensemble size \(N\) is typically much smaller than the dimensions \(D_{\vrv{x}}\) and \(D_{\vrv{y}}\), these costs are significantly lower than those incurred by the naive Kalman update.

By carefully ordering operations to work with the \(N\times N\) system, we thus achieve an update that is both computationally efficient and scalable to high-dimensional state spaces.

% \paragraph{Cost of the Naive Kalman Update:}
In a traditional Kalman filter, one computes the Kalman gain as
\[
\mm{K} = \mm{C}_{\vrv{xx}}\,\mm{H}^\top \Bigl(\mm{H}\,\mm{C}_{\vrv{xx}}\,\mm{H}^\top + \rho^2\mm{I}\Bigr)^{-1}.
\]
Here, the full observation covariance matrix \(\mm{H}\,\mm{C}_{\vrv{xx}}\,\mm{H}^\top + \rho^2\mm{I}\) is of size \(D_{\vrv{y}}\times D_{\vrv{y}}\). Forming this matrix typically costs on the order of \(O(D_{\vrv{x}}D_{\vrv{y}}^2)\) (assuming that \(\mm{C}_{\vrv{xx}}\) is dense) and inverting it requires \(O(D_{\vrv{y}}^3)\) operations. Thus, the naive update's cost is dominated by \(O(D_{\vrv{y}}^3)\) (plus the cost of computing \(\mm{H}\,\mm{C}_{\vrv{xx}}\,\mm{H}^\top\)), which can be substantially more expensive when \(D_{\vrv{y}}\) is large.

% \paragraph{Summary:}
The ensemble-based approach reduces the expensive inversion from an \(O(D_{\vrv{y}}^3)\) operation to one involving an \(N\times N\) matrix (costing \(O(N^3)\)), with additional costs \(O(D_{\vrv{y}}N^2)\) and \(O(D_{\vrv{x}}D_{\vrv{y}}N)\) from matrix multiplications. In contrast, the naive Kalman update requires inverting a \(D_{\vrv{y}}\times D_{\vrv{y}}\) matrix, which is significantly costlier when \(N \ll D_{\vrv{y}}\).

By exploiting the ensemble structure, we achieve an overall computational cost of
\[
    O\bigl(D_{\vrv{y}}N^2 + N^3 + D_{\vrv{x}}D_{\vrv{y}}N\bigr),
\]
which is much more scalable for high-dimensional problems compared to the \(O(D_{\vrv{y}}^3 + D_{\vrv{x}}D_{\vrv{y}}^2)\) cost of the naive Kalman update.

\section{Conclusion and Implications}

Understanding the EnKF as an empirical Matheron update opens up several possibilities, as both Matheron updates and Ensemble Kalman methods have been studied extensively in their respective domains.
Both have witnessed many developments in the Bayesian Machine learning setting
\citep{Alzraiee2022Scalable,Chada2022Convergence,Chen2021Autodifferentiable,Chen2023Reducedorder,Dunbar2022Ensemble,Guth2020Ensemble,Huang2022Iterated,Kovachki2019Ensemble,MacKinlay2025Gaussian,Oliver2022Hybrid,Schillings2017Analysis,Schneider2022Ensemble,Spantini2022Coupling}.
If we understand the pathwise update of the Matheron in the setting of the empirical measures used in Ensemble Kalman filters, this suggests the potential to import developments from each of these to the other.

The equivalence between the ensemble Kalman update and the empirical Matheron update offers several exciting avenues for further research. First, it provides a clear probabilistic interpretation of the ensemble update that may inspire improved regularization and localization strategies. For instance, by leveraging recent advances in sample-based conditioning and uncertainty quantification from the machine learning community, one might develop adaptive schemes that mitigate the effects of sampling error in high-dimensional settings.

Furthermore, this connection suggests that ideas developed in the context of Gaussian process inference—such as efficient sampling on Riemannian manifolds or the use of structured covariance approximations—could be imported into ensemble-based data assimilation frameworks. In particular, exploring extensions of the Matheron update beyond the Gaussian case (or for heavy-tailed error distributions) might lead to novel robust EnKF variants.

Finally, the computational benefits of the empirical formulation, notably the reduction to lower-dimensional inversions via the Woodbury identity, can be exploited in large-scale simulations. Future work will involve a systematic study of these benefits in practical applications, as well as a rigorous analysis of the approximation errors introduced by the finite ensemble size.

\section*{Acknowledgments}

% Acknowledgments can be added here.

\bibliographystyle{plainnat}
\bibliography{refs}

\appendix

\section{Measures as densities}\label{sec:densities-please}

In many machine learning and data assimilation applications, probability measures are represented via probability density functions (pdfs) with respect to the Lebesgue measure. For a continuous random variable \(\vrv{x}\) taking values in \(\mathbb{R}^{D_{\vrv{x}}}\), we denote its density by \(p_{\vrv{x}}(\vv{x})\) so that for any measurable set \(A \subset \mathbb{R}^{D_{\vrv{x}}}\),
\begin{equation}
    \Pr\left(\vrv{x} \in A\right)
    = \int_A p_{\vrv{x}}(\vv{x})\,\mathrm{d}\vv{x}.
\end{equation}
The expectation of any measurable function \(f:\mathbb{R}^{D_{\vrv{x}}}\to\mathbb{R}\) is given by
\begin{equation}
    \Ex[f(\vrv{x})] = \int_{\mathbb{R}^{D_{\vrv{x}}}} f(\vv{x})\,p_{\vrv{x}}(\vv{x})\,\mathrm{d}\vv{x}.
\end{equation}

We can write out the results of this paper in terms of densities, but since the primary object of our interst is the empirical measure and the moments of the theoretical and empirical measures, densities are not strictly necessary and result in a rather longer exposition.
Instead, we hope to reassure machine-learners that the two are equivalent in this appendix.

\subsection*{Dirac Functionals and Empirical Measures}

In many practical settings, we work with a finite sample \(\{\vv{x}^{(i)}\}_{i=1}^N\) drawn from the true distribution \(p_{\vrv{x}}(\vv{x})\). The empirical measure associated with this sample is defined as
\begin{equation}
    \widehat{P}_{\vrv{x}}(A) = \frac{1}{N} \sum_{i=1}^N \mathbf{1}_A(\vv{x}^{(i)}),
\end{equation}
where \(\mathbf{1}_A\) is the indicator function for the set \(A\). When we wish to express the empirical measure in density notation (with respect to the Lebesgue measure), we represent it as a sum of Dirac delta functions:
\begin{equation}
    p_{\text{emp}}(\vv{x}) = \frac{1}{N} \sum_{i=1}^N \delta(\vv{x}-\vv{x}^{(i)}).
\end{equation}

Note that the \emph{Dirac delta} is not a function in the classical sense but a \emph{distribution} (or generalized function). In functional analysis, a Dirac delta centered at \(\vv{x}^{(i)}\) is defined as a linear functional \(\delta_{\vv{x}^{(i)}}\) on a space of test functions (typically smooth functions with compact support) such that
\begin{equation}
    \langle \delta_{\vv{x}^{(i)}}, f \rangle = f(\vv{x}^{(i)}),
\end{equation}
for any test function \(f\). Here, the angle brackets \(\langle \cdot,\cdot \rangle\) denote the action of the distribution on \(f\). This \emph{sifting property} ensures that when integrating a test function against the empirical density, we recover the sample average:
\begin{equation}
    \int_{\mathbb{R}^{D_{\vrv{x}}}} f(\vv{x})\,p_{\text{emp}}(\vv{x})\,\mathrm{d}\vv{x}
    = \frac{1}{N} \sum_{i=1}^N \langle \delta_{\vv{x}^{(i)}}, f \rangle
    = \frac{1}{N} \sum_{i=1}^N f(\vv{x}^{(i)}).
\end{equation}

In this sense, the empirical measure is exactly the sum of Dirac functionals centered at each sample point, and the “density” \(p_{\text{emp}}\) should be understood in the distributional sense. This formulation is particularly useful when comparing the empirical measure to the true measure \(p_{\vrv{x}}\). Although the empirical measure is singular with respect to the Lebesgue measure (since it concentrates mass on a finite set of points), many operations (such as taking expectations of smooth functions) remain well-defined.

\subsection*{From Measures to Densities in Gaussian Conditioning}

For example, suppose the true prior for \(\vrv{x}\) is given by a density \(p_{\vrv{x}}(\vv{x})\) (say, a Gaussian)
\[
    p_{\vrv{x}}(\vv{x}) = \frac{1}{(2\pi)^{D_{\vrv{x}}/2} \,|\mm{C}_{\vrv{xx}}|^{1/2}} \exp\!\left(-\tfrac{1}{2}(\vv{x}-\vv{m}_{\vrv{x}})^\top \mm{C}_{\vrv{xx}}^{-1} (\vv{x}-\vv{m}_{\vrv{x}})\right),
\]
and the likelihood \(p_{\vrv{y}|\vrv{x}}(\vv{y}|\vv{x})\) is similarly specified. Then the joint density is
\begin{equation}
    p_{\vrv{x},\vrv{y}}(\vv{x},\vv{y})
    = p_{\vrv{x}}(\vv{x})\,p_{\vrv{y}|\vrv{x}}(\vv{y}|\vv{x}),
\end{equation}
and the conditional density is given by
\begin{equation}
    p_{\vrv{x}|\vrv{y}}(\vv{x}|\vv{y}^*)
    = \frac{p_{\vrv{x}}(\vv{x})\,p_{\vrv{y}|\vrv{x}}(\vv{y}^*|\vv{x})}{\int_{\mathbb{R}^{D_{\vrv{x}}}} p_{\vrv{x}}(\vv{x}')\,p_{\vrv{y}|\vrv{x}}(\vv{y}^*|\vv{x}')\,\mathrm{d}\vv{x}'}.
\end{equation}

In our work, while we initially denote measures by \(\Law[\cdot]\) (which emphasizes their abstract nature), one can equivalently work with the densities described above. When the empirical measure \(\ELaw[\mm{X}]\) is used to represent a sample of state vectors, its density is formally written as
\begin{equation}
    p_{\text{emp}}(\vv{x}) = \frac{1}{N} \sum_{i=1}^N \delta(\vv{x}-\vv{x}^{(i)}).
\end{equation}
Thus, updating the ensemble according to the empirical version of the Kalman or Matheron update can be seen as operating directly on these Dirac-based representations. In practical implementations, one does not manipulate the Dirac deltas directly; instead, one works with the sample values and their empirical moments, which—as shown earlier—are equivalent (in the limit of large \(N\)) to the full probabilistic update based on the density.

This density-based view, incorporating Dirac functionals to represent empirical measures, is particularly common in machine learning, where it provides an intuitive bridge between abstract measure-theoretic probability and the concrete computations performed with finite samples.



\end{document}
